{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RtISO1avpgV6"},"outputs":[],"source":["from bs4 import BeautifulSoup\n","import requests\n","import re\n","import pandas as pd\n","import os \n","\n","\n","#기업코드를 입력받아 기사의 제목을 100페이지까지 크롤링하는 함수\n","\n","def crawler(company_code, maxpage):\n","    \n","    page = 1 \n","    all_news= pd.DataFrame(columns={'날짜','언론사','기사제목','링크'})\n","    while page <= int(maxpage): \n","        \n","        url = 'https://finance.naver.com/item/news_news.nhn?code=' + str(company_code) + '&page=' + str(page) \n","        source_code = requests.get(url).text\n","        html = BeautifulSoup(source_code, \"lxml\")\n","\n","        # 뉴스 제목 \n","        titles = html.select('.title')\n","        title_result=[]\n","        for title in titles: \n","            title = title.get_text() \n","            title = re.sub('\\n','',title)\n","            title_result.append(title)\n"," \n"," \n","        # 뉴스 링크\n","        links = html.select('.title') \n"," \n","        link_result =[]\n","        for link in links: \n","            add = 'https://finance.naver.com' + link.find('a')['href']\n","            link_result.append(add)\n"," \n"," \n","        # 뉴스 날짜 \n","        dates = html.select('.date') \n","        date_result = [date.get_text() for date in dates] \n","\n"," \n","        # 뉴스 매체     \n","        sources = html.select('.info')\n","        source_result = [source.get_text() for source in sources] \n"," \n"," \n","        # 변수들 합쳐서 해당 디렉토리에 csv파일로 저장하기 \n","        \n","        result= {\"날짜\" : date_result, \"언론사\" : source_result, \"기사제목\" : title_result, \"링크\" : link_result} \n","        df_result = pd.DataFrame(result)\n","        \n","        all_news=pd.concat([all_news, df_result])\n","        \n","        print(\"다운 받고 있습니다------\")\n","        page += 1 \n","    all_news=all_news.drop_duplicates(['기사제목'])\n","    all_news.to_csv(str(company_code) + '.csv', mode='w', encoding='utf-8-sig') \n","    print('all_news')\n","    print(all_news)\n","\n","#train 데이터를 크롤링\n","train_df=pd.read_csv('train종목코드.csv')\n","train_df['종목코드']=train_df['CODE'].astype('str').str.zfill(6)\n","for i in train_df['종목코드']:\n","    crawler(i,100)\n","\n","#test 데이터를 크롤링\n","train_df=pd.read_csv('train종목코드.csv')\n","train_df['종목코드']=train_df['CODE'].astype('str').str.zfill(6)\n","for i in train_df['종목코드']:\n","    crawler(i,100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEftwO5dpgV9"},"outputs":[],"source":["def neg_rate(df):\n","    \n","    e_rates=[]\n","    s_rates=[]\n","    g_rates=[]\n","    \n","    for i in df['CODE']:\n","        path=f'{i}.csv'\n","        news= pd.read_csv(path)\n","\n","        e_count=0\n","        s_count=0\n","        g_count=0\n","        \n","        for t in news['기사제목']:\n","            e_list=['환경']\n","            s_list=['담합','불법파견','불매운동','불법고용','불공정거래','하도급문제','논란','골목상권 위협']\n","            g_list=['갑질','비리','뇌물','분식회계','비자금','일감몰아주기','배임','횡령','탈세','밀어내기','차명계좌','주가조작','성과급 잔치','구속','조세회피','내부자거래']\n","            \n","            if '환경' in t:\n","                e_count += 1\n","            elif ('담합'in t or '불법파견'in t or'불매운동' in t or'불법고용' in t or '불공정거래' in t or '하도급문제' in t or '논란'in t or '골목상권 위협' in t):\n","                s_count+=1\n","            elif ('갑질' in t or '비리'in t or '뇌물'in t or '분식회계' in t or '비자금' in t or '일감몰아주기' in t or '배임' in t or '횡령' in t or '탈세' in t or '밀어내기' in t or '차명계좌' in t or '주가조작' in t or '성과급 잔치' in t or '구속' in t or '조세회피' in t or '내부자거래'in t):\n","                g_count+=1\n","            e_rate= e_count / len(news['기사제목'])\n","            s_rate= s_count / len(news['기사제목'])\n","            g_rate= g_count / len(news['기사제목'])\n","            \n","        e_rates.append(e_rate)\n","        s_rates.append(s_rate)\n","        g_rates.append(g_rate)\n","            \n","    df['e 긍정뉴스 비율'] = e_rates\n","    df['s 부정뉴스 비율'] = s_rates\n","    df['g 부정뉴스 비율'] = g_rates\n","    \n","    news_df = df\n","    news_df.to_csv('train.csv',encoding=\"utf-8-sig\")\n","    return news_df"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}